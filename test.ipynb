{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8756901-719d-41b2-9cd9-9367f7cca93a",
   "metadata": {},
   "source": [
    "### Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb406e4-4a80-4cf3-8a30-19f98197c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from addiction import *\n",
    "from addiction.subject import *\n",
    "from addiction.utils import *\n",
    "from addiction.metrics import *\n",
    "from addiction.multimatch import *\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch_geometric.nn import GCNConv, GATConv, global_mean_pool, TopKPooling\n",
    "import torchvision.models as models\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib.patches import Rectangle\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a87d3fc-ab5a-4d1d-b5d1-686bdfe5ed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = Trainer(train_img_loader = train_img_loader,  valid_img_loader = valid_img_loader,  test_img_loader = test_img_loader, \n",
    "               train_gaze_loader = train_gaze_loader,  valid_gaze_loader = valid_gaze_loader, test_gaze_loader = test_gaze_loader,\n",
    "               batch_size = 64,  \n",
    "               env = Addiction_Env(), \n",
    "               policy = Generactor().double().to(device), \n",
    "               discriminator = Discriminator().double().to(device),\n",
    "               resume_from = '/root/autodl-tmp/exp/cirl/fold2_checkpoint_epoch_9_539.pth',\n",
    "               traj_net = TrajectoryGAT().double().to(device),\n",
    "               device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91010216-c722-4897-b9c6-273f4da0e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_labels(model, data_loader, device = device):\n",
    "    model = model.double().to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        label_table = {}\n",
    "        for data in data_loader:\n",
    "            # data['traj_data'].x = data['traj_data'].x.double().to(device)\n",
    "            probs = model(data['traj_data'].to(device)).detach().cpu()\n",
    "            probs = torch.exp(probs)  \n",
    "            probs = probs / probs.sum(dim=1).unsqueeze(1)   \n",
    "            subjects = data['subject'].tolist()\n",
    "            trail_indices = data['trail_index'].tolist()\n",
    "            cues = torch.sum(torch.stack(data['cues']), dim = 0).tolist()\n",
    "            label_table.update({(subj, trail_idx, cue): prob for subj, trail_idx, cue, prob in zip(subjects, trail_indices, cues, probs)})\n",
    "    return label_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e404ce-420a-4f76-8e84-882646d9a2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_saliency = {}\n",
    "def get_human_gaze(gaze_data, human_saliency):\n",
    "    for data in gaze_data:\n",
    "        done = (data['end'] == 1)\n",
    "        if done.sum() == 0:\n",
    "            continue\n",
    "        subjects = data['subject']\n",
    "        index = data['trail_index']\n",
    "        cues = torch.sum(torch.stack(data['cues']), dim = 0)\n",
    "        saliency_maps = data['saliency_map']\n",
    "        for sub, idx, cue, sal in zip(subjects, index, cues, saliency_maps):\n",
    "            key = (sub.item(), idx.item(), cue.item())\n",
    "            # sal = normalize_map(sal.detach().cpu().numpy())\n",
    "            human_saliency[key] = sal.detach().cpu().numpy()\n",
    "    return human_saliency\n",
    "human_saliency = get_human_gaze(train_gaze_loader, human_saliency)   \n",
    "human_saliency = get_human_gaze(valid_gaze_loader, human_saliency)\n",
    "human_saliency = get_human_gaze(test_gaze_loader,  human_saliency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f97f402-a4d2-4a66-9bb9-34358ac6f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = []\n",
    "all_actions = []\n",
    "for i_sample in range(10):\n",
    "    for i_batch, batch in enumerate(self.test_img_loader):\n",
    "        batch_soft_label = torch.stack([label_tables[(subj.item(), idx.item(), cue.item())]\n",
    "            for subj, idx, cue in zip(batch['subject'], batch['trail_index'], torch.sum(torch.stack(batch['cues']), dim = 0))\n",
    "            if (subj.item(), idx.item(), cue.item()) in label_tables\n",
    "        ], dim = -1).T\n",
    "        batch['soft_label'] = batch_soft_label\n",
    "        self.env.set_data(batch)\n",
    "        with torch.no_grad():\n",
    "            self.env.reset()\n",
    "            trajs = collect_trajs(self.env, self.generator.to(self.device), self.max_traj_len)\n",
    "            for sub, idx, cue, traj, label in zip(batch['subject'], batch['trail_index'], torch.sum(torch.stack(batch['cues']), dim = 0), trajs, batch['label']):\n",
    "                if (sub.item(), idx.item(), cue.item()) in human_saliency:\n",
    "                    agent_scanpath = torch.cat([self.env.init_fix[0].unsqueeze(0), traj['actions'].to(env.device)]).cpu().numpy()\n",
    "                    human_scanpath = human_scanpaths[(sub.item(), idx.item(), cue.item())]\n",
    "                    agent_scanpath = {'X': agent_scanpath[:,0],'Y': agent_scanpath[:,1],'T':agent_scanpath[:,2]}\n",
    "                    human_scanpath = {'X': human_scanpath[:,0],'Y': human_scanpath[:,1],'T':human_scanpath[:,2]}\n",
    "                    mm_score = multimatch(agent_scanpath, human_scanpath, im_size = (1080, 1920))\n",
    "                    mms.append(mm_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
